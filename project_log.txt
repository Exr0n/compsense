<entry name="first thoughts">
  It's 18 April 2019 and computers are cool. Can we get them to extrapolate information?

  Goal: Read the first line of a bunch of wikipedia pages, then parse them and somehow "remember" that information. Then, output a sentence of "common sense" that fits in with other things on conceptnet.io

  Is it doable? Probably.
  Can I do it? Probably not.

  Lets get started!
</entry>

<entry name="reality sinks in">
  So some smart people have done some cool stuff... like deepmind.

  But I want to tackle a different problem: Can we get the computer to make a "web" of information? Something like how the brain forms a "web" of knowledge?
  What I mean is: we think of things as connected to other things, and so when you think of a word many others come to mind.

  =============================================================================================================================
  + THE (main) PROBLEM: What kind of storage or "memory" system needs to be in place to allow for this kind of connectedness? +
  =============================================================================================================================

  Some kind of node like system is what comes to mind, but what does that even mean in a computing sense?
  I suppose we have to use Google's natural language API, because that will make things alot easier. It categorizes things and assigns relations to them. Maybe it even solved this problem, and I just did'nt notice.
  (I hope not, that would be pretty akward.)

  Anyways, I need to do more thinking. Cyan!
</entry>

<entry name="first tangable ideas">
  We learn and think with nodes, right?
  What if the computer stored nodes that have connections with other nodes, and those connections get stronger when the computer sees two "linked" concepts?
  This is pretty much a model at our current guess of how the brain works. Right?

  I was thinking that there could be different types of connections, like -1 < meaning < 1 connections and -1 < sentiment < 1 connections, etc,
    but that seems to defeat the whole point.

  After all, the goal is to not constrain the computer, and putting in those categories for it would make the first part easy but limit it in the future.
  It needs to learn the categories for itself. The problem is how?

  That needs to be thought out more...

  Anyways, I was thinking there are three main "layers" or "steps" to this whole thing.
    1. Analyze text (wikipedia, other sources maybe) and have some understanding of how concepts relate  (Google NatLang API already does this pretty well)
    2. Encode this basic understanding in a network of nodes, with a node for each concept.
      We want the network to be able to help with understanding new material, so it should tie back into the NatLang system if possible. But this is a next step.
    3. After the network learns a bunch of stuff, look at some of the nodes and how they are connected, to see what the network "knows".
      It would be really nice for us to be able to just ask the network what it knows about stuff, but that might be difficult.

  So that's the big picture overview. Here are the next steps:
    1. Flush out the idea of computer generated connections, and how they would work.
      This seems like the "correct" way to solve this problem, and I refuse to compromise. I don't know why, but I have this strong gut feeling that we should leave
      the connection types up to the computer.
    2. Write a preliminary class structure for the "knowledge net", or step 2. This is the meat of the project.
    3. Figure out how exactly to use the Google NatLang API and how to shove its output into the knownet.
    4. Think more about how we can get an output from the net. I wan't it to have simple statements like conceptnet, but I don't know exactly how that would work.

  To give a sense of time, I don't expect to get to step 4 until well into 2020. And I hope I don't give up before then...

  As of yet, I'm still really excited about this. More thinking is to be done. Cyan!
</entry>

<entry name="multi layer system?">
  I was doing even more thinking and I think I have an idea for how to make the relations change dynamically. The answer? More learning!
  Basically we originally had a network of concepts connected by relations. Originally, there was going to be just one type of relation, a value from -1 to 1.
  But then, I looked at conceptnet more and they have a huge variety of different relations, and those different types of relations really form the backbone of the "intuition".
  So it seems clear that we also need those different relations. The problem is that on conceptnet, those relations are generated by humans (i think?) and that's bad,
    because human input is the thing that we are trying to solve here.
  So what we have to do is make a network of relations, that are related to each other with other relations. Importantly, the other relations are not meta-relations. That would
    just cause the problem to be moved down a level. Instead, those relations are simply the same level of relations as before.
  That way, we won't have an infinite downwards spiral of crazy memory usage.

  There seem to be a few glaring problems with this system off in the distance, but I can't quite make them out through all the fog. I guess we will figure it out when it gets there!
  (Even if it means starting over (I hope not (get ready for a lot of closing parenthesis (')'))))

  So yeah, thats the concept update for now. Im gonna start figuring out the class structure and how everything is actually gonna get put together. But until then, cyan!
</entry>

<entry name="the first revelation (maybe?)">
  In the process of coding the thing, I think I figured out how to solve the issue that was nagging at me.

  So the issue was this: why separate everything into concepts and relations? That seems a bit arbitrary, don't you?
    And even if it doesn't, how do we know this separation is not just a limitation of our own brains? Why should we limit knonet like that?
  The system was originally devised because that's how I thought conceptnet worked, and conceptnet is basically the thing that I want to end up with.
    (but like, automatically without crowdsourced info)
  But it turns out, conceptnet also has pages for the concepts that form the relations. Things like "capable".
  The thing is, on the pages the relations are still nicely separated out from the things that are normally separated out as "concepts". I think we can do better:

  So here's the master plan (v 0.0.1.1)

    Instead of having concepts and relations, relations will be concepts. This allows for more flexibility and creativity on knonet's part.
    We can treat connections between concepts as paths in a graph. The concepts connect to each other "via" other concepts,
    and each connection along the "route" will have strengths that are somehow related to the end strength of the connection through concepts.
    In other words, each concepts will have a relation with other concepts, and this relation somehow interacts with some routes that can be formed between concepts through other concepts.
    Importantly, two concepts can be connected through multiple routes, and the particularities of those routes somehow interact with the final connection.

  There are alot of question marks flying around in my brain right now, and they are stirring up the fog. It's getting harder and harder to see, but I think we've turned slightly
  and are now facing a new direction. There are still dark shapes in the distance, but they seem further away now. I think this is the way to go.

  Im gonna keep hacking away at the code until I fall asleep on my keyboard. Maybe something new will pop up in my insomnia.
  But until then, cyan!
</entry>

<entry name="more inspiration from nature">
  So I mocked up what I was thinking, but I realized that it was kinda stupid.
  Well, its pretty cool but like it is set up in a way that makes it hard to integrate with the output of current natural language tech, which is the whole point.
  Instead, I have an idea for a modification: instead of having separate systems for updating connection weights and a feed method, we can have the feed update the connection weights.
  This was kind of implemented in the old system but not in a very effective way, and honestly, it was just a sleep deprived kind of "hey we should do this right? probably? eh?".

  This version will be the first major theory change, so we shall call it "alpha 0.0.2"

  Anyways, heres the new plan:
    Relation strengths are between -1 and 1, inclusive. (Im not sure if I mentioned that before, but thats how it will work for this revision.)
    A concept receiving a "pulse" from a relation will not propagate that pulse unless it is greater than 0.
      The "greater than 1" from the above line is calculated with a formula, something along the lines of `squishify(pulse.strength + concept.bias)`
      As you can see, I don't know enough math to come up with a good formula. That was basically ripped out of the bog standard ANN, but this is a point for improvement.
    A relation that carries a pulse gets its strength modified, to simulate "neurons that fire together wire together". Something like `squishify(relation.strength * pulse.strength)`
      The only glaring problem I see with this right now is that a relation cannot get its strength flipped from positive to negative, which seems bad. That needs to be fixed somehow...

  So the reason I have the second rule is so that two nodes can't just fire back and forth at eachother, like a dog and a cat. But writing this sentence,
    I realize that actually that doesn't actually fix the problem. This needs to be worked on.

  Problems with this plan that need to be kinked out:
    Concepts can fire back and forth at each other, is there an elegant way to eliminate this that is similar to how actual brains work? (or atleast my understanding of how I think they should work?)
    Relation strength sign flipping, make it possible but not cause other issues
    Doing something like that but involve routes? or delete routes all together

  Also, I dreamed up some problems that are probably gonna choke out poor knonet. Here they are:

  Kinda Really Big Problems (KiRBiP):
    Dealing with words that are the same spelling but different meanings
    Multi-word tokenization? Putting words together to form more complex concepts
    Collected/consolidated firings: Actual neurons can be inhibited, but these concepts can't.
      Can we "buffer" received pulses and calculate some kind of collective pulse strength to pass on?
      This seems correct because that's how neurons work irl, but maybe our concept system already abstracts this enough that it's uneeded...

  So I suppose the next step is to implement those above changes and again brainstorm how to solve our need kinking problems. That's what I will work on next.
  But until I have more to say, cyan!
</entry>
